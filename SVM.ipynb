{"cells":[{"cell_type":"code","execution_count":100,"metadata":{"id":"hIkdS2u56KdD"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n"]},{"cell_type":"markdown","metadata":{"id":"BxDSoMT640Oo"},"source":["## Atividade 1\n","\n",">**Implemente uma classe que corresponda ao SVM**"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"-4DM4aP_1cn8"},"outputs":[],"source":["class SVM:\n","    def __init__(self, kernel='linear', C=1.0, gamma=None, degree=3, coef0=1, learning_rate=0.001, n_iters=1000):\n","        self.kernel = kernel\n","        self.C = C\n","        self.gamma = gamma\n","        self.degree = degree\n","        self.coef0 = coef0\n","        self.learning_rate = learning_rate\n","        self.n_iters = n_iters\n","        self.w = None\n","        self.b = None\n","        self.alpha = None\n","        self.K = None\n","\n","    def _kernel(self, x1, x2):\n","        if self.kernel == 'linear':\n","            return np.dot(x1, x2)\n","        elif self.kernel == 'poly':\n","            return (np.dot(x1, x2) + self.coef0) ** self.degree\n","        elif self.kernel == 'rbf':\n","            return np.exp(-self.gamma * np.linalg.norm(x1 - x2) ** 2)\n","        else:\n","            raise ValueError(f\"Unsupported kernel type: {self.kernel}\")\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self.alpha = np.zeros(n_samples)\n","        self.b = 0\n","        y_ = np.where(y <= 0, -1, 1)\n","\n","        self.K = np.zeros((n_samples, n_samples))\n","        for i in range(n_samples):\n","            for j in range(n_samples):\n","                self.K[i, j] = self._kernel(X[i], X[j])\n","\n","        for _ in range(self.n_iters):\n","            for i in range(n_samples):\n","                gradient = 1 - y_[i] * (np.sum(self.alpha * y_ * self.K[:, i]) + self.b)\n","                if self.alpha[i] < self.C:\n","                    self.alpha[i] += self.learning_rate * gradient\n","\n","        if self.kernel == 'linear':\n","            self.w = np.dot(X.T, self.alpha * y_)\n","            self.b = np.mean(y_ - np.dot(self.K, self.alpha * y_))\n","\n","    def project(self, X):\n","        if self.kernel == 'linear':\n","            return np.dot(X, self.w) + self.b\n","        else:\n","            y_predict = np.zeros(X.shape[0])\n","            for i in range(X.shape[0]):\n","                sum_alpha_kernel = np.sum(self.alpha * np.array([self._kernel(X[i], X_train[j]) for j in range(X_train.shape[0])]))\n","                y_predict[i] = sum_alpha_kernel\n","            return y_predict + self.b\n","\n","\n","\n","    def predict(self, X):\n","        return np.sign(self.project(X))\n","\n","    def evaluate(self, X_test, y_test):\n","        y_predict = self.predict(X_test)\n","        accuracy = np.mean(y_predict == y_test)\n","        return accuracy\n","   "]},{"cell_type":"markdown","metadata":{"id":"K87CA5BA5ur2"},"source":["## **Atividade 2 - Classificação com o dataset Iris**\n","\n","Features: Total de 4\n","\n","Para essa atividade utilizar as features:\n","1. Comprimento do sépalo (sepal length)\n","2. Largura do sépalo (sepal width)\n","3. Comprimento da pétala (petal length)\n","4. Largura da pétala (petal width)\n","\n","Variável dependente: Espécie da flor Iris (Setosa, Versicolor ou Virginica)\n","\n","\n",">**Treine os dados da base Iris utilizando SVM implementado**\n","\n",">**Faça as predições nos dados de teste e compare os dados reais com os preditos**"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1719093235295,"user":{"displayName":"Gabriely Lima","userId":"08647796047239960191"},"user_tz":180},"id":"5kr_XbQw5uVX","outputId":"3e521cb0-48a0-467c-f196-a3cc9814ab81"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length</th>\n","      <th>sepal width</th>\n","      <th>petal length</th>\n","      <th>petal width</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 4 columns</p>\n","</div>"],"text/plain":["     sepal length  sepal width  petal length  petal width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.7          3.2           1.3          0.2\n","3             4.6          3.1           1.5          0.2\n","4             5.0          3.6           1.4          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[150 rows x 4 columns]"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["# Carregando o conjunto de dados Iris\n","data = load_iris()\n","colunas = ['sepal length', 'sepal width', 'petal length', 'petal width']\n","pd.DataFrame(data['data'], columns=colunas)"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Avaliação com dados não normalizados:\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       0.80      0.62      0.70        13\n","   virginica       0.69      0.85      0.76        13\n","\n","    accuracy                           0.84        45\n","   macro avg       0.83      0.82      0.82        45\n","weighted avg       0.85      0.84      0.84        45\n","\n","Real:     [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n"," 0 0 0 2 1 1 0 0]\n","Predito:  [1 0 1 2 1 0 2 2 1 1 2 0 0 0 0 2 2 1 1 2 0 2 0 2 2 2 1 2 0 0 0 0 1 0 0 2 2\n"," 0 0 0 2 2 1 0 0]\n","\n"," Acurácia do modelo: 84.44%\n"]}],"source":["iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, random_state=42)\n","\n","# Função para treinar e avaliar o modelo SVM no esquema one-vs-rest\n","def train_and_evaluate_svm(X_train, y_train, X_test, y_test):\n","    svms = []\n","    for i in np.unique(y_train):\n","        y_train_binary = np.where(y_train == i, 1, -1)\n","        svm = SVM(kernel='linear')\n","        svm.fit(X_train, y_train_binary)\n","        \n","        svms.append(svm)\n","\n","    # Predizer as classes no conjunto de teste\n","    y_pred = np.zeros(X_test.shape[0])\n","    confidences = np.zeros((X_test.shape[0], len(svms)))\n","    for i, svm in enumerate(svms):\n","        confidences[:, i] = svm.project(X_test)\n","    y_pred = np.argmax(confidences, axis=1)\n","\n","    print(\"Classification Report:\")\n","    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n","    return y_pred\n","\n","print(\"Avaliação com dados não normalizados:\")\n","y_pred = train_and_evaluate_svm(\n","    X_train, y_train, X_test, y_test)\n","# Comparar os dados reais com os preditos\n","print(\"Real:    \", y_test)\n","print(\"Predito: \", y_pred)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\n Acurácia do modelo: {accuracy * 100:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"YibuswQm9Ddv"},"source":[">**Normalize os dados da base Iris e refaça o treinamento do modelo**\n","\n","Compare os resultados dos dados normalizados e não normalizados. Como métricas de avaliação podem utilizar recall, precision e f-measure."]},{"cell_type":"code","execution_count":106,"metadata":{"id":"k4K3Snzz9CtR"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Avaliação com dados normalizados:\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       0.67      0.46      0.55        13\n","   virginica       0.59      0.77      0.67        13\n","\n","    accuracy                           0.78        45\n","   macro avg       0.75      0.74      0.74        45\n","weighted avg       0.78      0.78      0.77        45\n","\n"]}],"source":["# Normalizar os dados\n","scaler = StandardScaler()\n","X_train_normalized = scaler.fit_transform(X_train)\n","X_test_normalized = scaler.transform(X_test)\n","\n","# Treinar e avaliar o modelo com dados normalizados\n","print(\"\\nAvaliação com dados normalizados:\")\n","y_pred_normalized = train_and_evaluate_svm(X_train_normalized, y_train, X_test_normalized, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Comparação de Resultados:\n","\n","Dados Não Normalizados:\n","Precision: 85.19%\n","Recall: 84.44%\n","F1-Score: 84.23%\n","Accuracy: 84.44%\n","\n","Dados Normalizados:\n","Precision: 78.47%\n","Recall: 77.78%\n","F1-Score: 77.24%\n","Accuracy: 77.78%\n"]}],"source":["# Comparar os resultados dos dados normalizados e não normalizados\n","def compare_results(y_test, y_pred_non_normalized, y_pred_normalized):\n","    print(\"\\nComparação de Resultados:\")\n","\n","    print(\"\\nDados Não Normalizados:\")\n","    precision_non_normalized = precision_score(y_test, y_pred_non_normalized, average='weighted')\n","    recall_non_normalized = recall_score(y_test, y_pred_non_normalized, average='weighted')\n","    f1_non_normalized = f1_score(y_test, y_pred_non_normalized, average='weighted')\n","    accuracy_non_normalized = accuracy_score(y_test, y_pred_non_normalized)\n","    \n","    print(f\"Precision: {precision_non_normalized*100:.2f}%\")\n","    print(f\"Recall: {recall_non_normalized*100:.2f}%\")\n","    print(f\"F1-Score: {f1_non_normalized*100:.2f}%\")\n","    print(f\"Accuracy: {accuracy_non_normalized*100:.2f}%\")\n","\n","    print(\"\\nDados Normalizados:\")\n","    precision_normalized = precision_score(y_test, y_pred_normalized, average='weighted')\n","    recall_normalized = recall_score(y_test, y_pred_normalized, average='weighted')\n","    f1_normalized = f1_score(y_test, y_pred_normalized, average='weighted')\n","    accuracy_normalized = accuracy_score(y_test, y_pred_normalized)\n","    \n","    print(f\"Precision: {precision_normalized*100:.2f}%\")\n","    print(f\"Recall: {recall_normalized*100:.2f}%\")\n","    print(f\"F1-Score: {f1_normalized*100:.2f}%\")\n","    print(f\"Accuracy: {accuracy_normalized*100:.2f}%\")\n","\n","compare_results(y_test, y_pred, y_pred_normalized)"]},{"cell_type":"markdown","metadata":{"id":"CsfI4rYW8R-a"},"source":[">**Divida o dataset em treinamento, teste e validação. Escreva um código que escolhe os melhores hiperparâmetros ajustando o conjunto de validação.**\n","\n","Por exemplo qual o melhor Kernel vizinho (linear, poly, rbf), qual a melhor C, gamma. Como métricas de avaliação podem utilizar recall, precision e f-measure."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carregar o dataset Iris\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Mapear rótulos para binário: Setosa (-1) vs. não-Setosa (1)\n","y_binary = np.where(y == 0, -1, 1)\n","\n","# Normalizar as features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","\n","# Dividir o dataset em treinamento, teste e validação\n","X_train_val, X_test, y_train_val, y_test = train_test_split(\n","    X, y_binary, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n","\n","\n","# Definir listas de valores para os hiperparâmetros a serem testados\n","kernels = ['linear', 'poly', 'rbf']\n","Cs = [0.1, 1, 10]\n","gammas = [0.1, 1, 10]\n","\n","best_score = -1\n","best_params = None\n","\n","# Loop para testar todas as combinações de hiperparâmetros\n","for kernel in kernels:\n","    for C in Cs:\n","        for gamma in gammas:\n","            # Instanciar e treinar o modelo SVM com os hiperparâmetros atuais\n","            svm = SVM(kernel=kernel, C=C, gamma=gamma,\n","                      learning_rate=0.001, n_iters=1000)\n","            svm.fit(X_train, y_train)\n","\n","            # Avaliar no conjunto de validação\n","            y_pred_val = svm.predict(X_val)\n","            f1 = f1_score(y_val, y_pred_val, average='weighted')\n","\n","            # Calcular outras métricas se necessário (precision, recall, f-measure)\n","            accuracy = accuracy_score(y_val, y_pred_val)\n","            precision = precision_score(y_val, y_pred_val)\n","            recall = recall_score(y_val, y_pred_val)\n","            f_measure = f1_score(y_val, y_pred_val)\n","\n","            # Exibir os resultados para cada combinação de hiperparâmetros\n","            print(f\"Kernel: {kernel}, C: {C}, gamma: {gamma}\")\n","            print(\n","                f\"Acurácia: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F-measure: {f_measure:.2f}\")\n","            print(\"\")\n","\n","            # Verificar se é a melhor combinação de hiperparâmetros até agora\n","            if f1 > best_score:\n","                best_score = f1\n","                best_params = {'kernel': kernel, 'C': C, 'gamma': gamma}\n","\n","# Usar os melhores hiperparâmetros encontrados para treinar o modelo final\n","best_model = SVM(**best_params)\n","best_model.fit(X_train, y_train)\n","\n","# Avaliar no conjunto de teste\n","test_accuracy = best_model.evaluate(X_test, y_test)\n","print(f\"Melhores hiperparâmetros: {best_params}\")\n","print(f\"Acurácia no conjunto de teste: {test_accuracy*100:.2f}%\")"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Kernel: linear, C: 0.1, gamma: 0.001\n","Acurácia: 0.80, Precision: 0.89, Recall: 0.80, F1-Score: 0.80\n","\n","Kernel: linear, C: 0.1, gamma: 0.01\n","Acurácia: 0.80, Precision: 0.89, Recall: 0.80, F1-Score: 0.80\n","\n","Kernel: linear, C: 0.1, gamma: 0.1\n","Acurácia: 0.80, Precision: 0.89, Recall: 0.80, F1-Score: 0.80\n","\n","Kernel: linear, C: 1, gamma: 0.001\n","Acurácia: 0.83, Precision: 0.87, Recall: 0.83, F1-Score: 0.83\n","\n","Kernel: linear, C: 1, gamma: 0.01\n","Acurácia: 0.83, Precision: 0.87, Recall: 0.83, F1-Score: 0.83\n","\n","Kernel: linear, C: 1, gamma: 0.1\n","Acurácia: 0.83, Precision: 0.87, Recall: 0.83, F1-Score: 0.83\n","\n","Kernel: linear, C: 10, gamma: 0.001\n","Acurácia: 0.77, Precision: 0.83, Recall: 0.77, F1-Score: 0.77\n","\n","Kernel: linear, C: 10, gamma: 0.01\n","Acurácia: 0.77, Precision: 0.83, Recall: 0.77, F1-Score: 0.77\n","\n","Kernel: linear, C: 10, gamma: 0.1\n","Acurácia: 0.77, Precision: 0.83, Recall: 0.77, F1-Score: 0.77\n","\n","Kernel: poly, C: 0.1, gamma: 0.001\n","Acurácia: 0.60, Precision: 0.77, Recall: 0.60, F1-Score: 0.48\n","\n","Kernel: poly, C: 0.1, gamma: 0.01\n","Acurácia: 0.60, Precision: 0.77, Recall: 0.60, F1-Score: 0.48\n","\n","Kernel: poly, C: 0.1, gamma: 0.1\n","Acurácia: 0.60, Precision: 0.77, Recall: 0.60, F1-Score: 0.48\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: poly, C: 1, gamma: 0.001\n","Acurácia: 0.50, Precision: 0.35, Recall: 0.50, F1-Score: 0.41\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: poly, C: 1, gamma: 0.01\n","Acurácia: 0.50, Precision: 0.35, Recall: 0.50, F1-Score: 0.41\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: poly, C: 1, gamma: 0.1\n","Acurácia: 0.50, Precision: 0.35, Recall: 0.50, F1-Score: 0.41\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: poly, C: 10, gamma: 0.001\n","Acurácia: 0.50, Precision: 0.35, Recall: 0.50, F1-Score: 0.41\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: poly, C: 10, gamma: 0.01\n","Acurácia: 0.50, Precision: 0.35, Recall: 0.50, F1-Score: 0.41\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: poly, C: 10, gamma: 0.1\n","Acurácia: 0.50, Precision: 0.35, Recall: 0.50, F1-Score: 0.41\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 0.1, gamma: 0.001\n","Acurácia: 0.30, Precision: 0.09, Recall: 0.30, F1-Score: 0.14\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 0.1, gamma: 0.01\n","Acurácia: 0.30, Precision: 0.09, Recall: 0.30, F1-Score: 0.14\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 0.1, gamma: 0.1\n","Acurácia: 0.30, Precision: 0.10, Recall: 0.30, F1-Score: 0.15\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 1, gamma: 0.001\n","Acurácia: 0.30, Precision: 0.09, Recall: 0.30, F1-Score: 0.14\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 1, gamma: 0.01\n","Acurácia: 0.43, Precision: 0.19, Recall: 0.43, F1-Score: 0.26\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 1, gamma: 0.1\n","Acurácia: 0.43, Precision: 0.19, Recall: 0.43, F1-Score: 0.26\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 10, gamma: 0.001\n","Acurácia: 0.43, Precision: 0.19, Recall: 0.43, F1-Score: 0.26\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Kernel: rbf, C: 10, gamma: 0.01\n","Acurácia: 0.43, Precision: 0.19, Recall: 0.43, F1-Score: 0.26\n","\n","Kernel: rbf, C: 10, gamma: 0.1\n","Acurácia: 0.43, Precision: 0.19, Recall: 0.43, F1-Score: 0.26\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Pichau\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","# Função para treinar e avaliar o modelo SVM no esquema one-vs-rest\n","def train_and_evaluate_svm_with_hyperparams(X_train, y_train, X_val, y_val, kernel, C, gamma):\n","    # Inicializar SVMs one-vs-rest para cada classe\n","    svms = []\n","    for i in np.unique(y_train):\n","        y_train_binary = np.where(y_train == i, 1, -1)\n","        svm = SVM(kernel=kernel, C=C, gamma=gamma)\n","        svm.fit(X_train, y_train_binary)\n","        svms.append(svm)\n","\n","    # Predizer as classes no conjunto de validação\n","    y_val_pred = np.zeros(X_val.shape[0])\n","    confidences = np.zeros((X_val.shape[0], len(svms)))\n","    for i, svm in enumerate(svms):\n","        confidences[:, i] = svm.project(X_val)\n","    y_val_pred = np.argmax(confidences, axis=1)\n","\n","    # Calcular métricas\n","    precision = precision_score(y_val, y_val_pred, average='weighted')\n","    recall = recall_score(y_val, y_val_pred, average='weighted')\n","    f1 = f1_score(y_val, y_val_pred, average='weighted')\n","    accuracy = accuracy_score(y_val, y_val_pred)\n","    \n","    # Exibir os resultados para cada combinação de hiperparâmetros testada\n","    print(f\"Kernel: {kernel}, C: {C}, gamma: {gamma}\")\n","    print(f\"Acurácia: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n","    print(\"\")\n","\n","# Definir a grade de parâmetros para busca\n","param_grid = {\n","    'kernel': ['linear', 'poly', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'gamma': [0.001, 0.01, 0.1]\n","}\n","\n","# Dividir os dados em conjuntos de treinamento, validação e teste\n","X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n","\n","# Normalizar os dados\n","X_train_normalized = scaler.fit_transform(X_train)\n","X_val_normalized = scaler.transform(X_val)\n","X_test_normalized = scaler.transform(X_test)\n","\n","# Realizar a busca pelos melhores hiperparâmetros\n","for kernel in param_grid['kernel']:\n","    for C in param_grid['C']:\n","        for gamma in param_grid['gamma']:\n","            train_and_evaluate_svm_with_hyperparams(\n","                X_train_normalized, y_train, X_val_normalized, y_val, kernel, C, gamma)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMnDiZhYaBsiMrLx7lWVGjj","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
